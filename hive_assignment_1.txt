##author: Kunal Nayyar ##
## Hive Assignment 1 ##
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
1. Download vehicle sales data -> https://github.com/shashank-mishra219/Hive-Class/blob/main/sales_order_data.csv
2. Store raw data into hdfs location
>hadoop fs -mkdir /tmp/hive/rawdata
>hadoop fs -copyFromLocal sales_order_data.csv /tmp/hive/rawdata/

3. Create an internal hive table "sales_order_csv" which will store csv data sales_order_csv ... make sure to skip header row while creating table
>create table sales_order_csv(ORDERNUMBER int,QUANTITYORDERED int,PRICEEACH float,ORDERLINENUMBER int,SALES float,STATUS string,QTR_ID int,MONTH_ID int,YEAR_ID int,PRODUCTLINE string,MSRP int,PRODUCTCODE string,PHONE string,CITY string,STATE string,POSTALCODE string,COUNTRY string,TERRITORY string,CONTACTLASTNAME string,
CONTACTFIRSTNAME string,DEALSIZE string) row format delimited fields terminated by ',' tblproperties('skip.header.line.count' = '1');

4. Load data from hdfs path into "sales_order_csv" 
>load data inpath '/tmp/hive/rawdata/' to table sales_order_csv;

5. Create an internal hive table which will store data in ORC format "sales_order_orc"
> create table sales_order_orc(ORDERNUMBER int,QUANTITYORDERED int,PRICEEACH float,ORDERLINENUMBER int,SALES float,STATUS string,QTR_ID int,MONTH_ID int,YEAR_ID int,PRODUCTLINE string,MSRP int,PRODUCTCODE string,PHONE string,CITY string,STATE string,POSTALCODE string,COUNTRY string,TERRITORY string,CONTACTLASTNAME string,CONTACTFIRSTNAME string,DEALSIZE string) stored as orc;

6. Load data from "sales_order_csv" into "sales_order_orc"
>from sales_order_csv insert overwrite table sales_order_orc select *;

7.Perform below mentioned queries on "sales_order_orc" table:
a. Calculate total sales per year
>select sum(sales), year_id from sales_order_orc group by year_id;
3516979.547241211	2003
4724162.593383789	2004
1791486.7086791992	2005

b. Find a product for which maximum orders were placed
>select count(productcode) as totalorders,productcode from sales_order_orc group by productcode order by totalorders desc limit 1;
totalorders	productcode
52	S18_3232

c. Calculate the total sales for each quarter
>select sum(sales) as totalsales,qtr_id as quarter from sales_order_orc group by qtr_id order by qtr_id;
totalsales	quarter
2350817.726501465	1
2048120.3029174805	2
1758910.808959961	3
3874780.010925293	4

d. In which quarter sales was minimum
> select sum(sales) as totalsales,qtr_id as quarter from sales_order_orc group by qtr_id order by totalsales limit 1;
totalsales	quarter
1758910.808959961	3

e. In which country sales was maximum and in which country sales was minimum
>select sum(sales) as totalsales,country from sales_order_orc group by country order by totalsales limit 1;
totalsales	country
57756.43029785156	Ireland
>select sum(sales) as totalsales,country from sales_order_orc group by country order by totalsales desc limit 1;
totalsales	country
3627982.825744629	USA

f. Calculate quarterly sales for each city
> select sum(sales) as quaterlysales,city,qtr_id as quarter from sales_order_orc group by city,qtr_id order by city,qtr_id limit 20;
quaterlysales	city	quarter
100595.5498046875	Aaarhus	4
6166.7998046875	Allentown	2
71930.61041259766	Allentown	3
44040.729736328125	Allentown	4
4219.2001953125	Barcelona	2
74192.66003417969	Barcelona	4
56181.320068359375	Bergamo	1
81774.40008544922	Bergamo	4
16363.099975585938	Bergen	3
95277.17993164062	Bergen	4
31606.72021484375	Boras	1
53941.68981933594	Boras	3
48710.92053222656	Boras	4
74994.240234375	Boston	2
15344.640014648438	Boston	3
63730.7802734375	Boston	4
31474.7802734375	Brickhaven	1
7277.35009765625	Brickhaven	2
114974.53967285156	Brickhaven	3
11528.52978515625	Brickhaven	4

h. Find a month for each year in which maximum number of quantities were sold
>create table t2 as with q1 as (select sum(quantityordered) as monthlyquantity,year_id,month_id from sales_order_orc group by year_id,month_id order by year_id,month_id) select monthlyquantity,month_id,year_id from q1 where q1.monthlyquantity in (select max(monthlyquantity) from q1 group by year_id);
Total MapReduce CPU Time Spent: 7 seconds 610 msec
>select * from t2; 
t2.monthlyquantity	t2.month_id	t2.year_id
10179	11	2003
10678	11	2004
4357	5	2005

[or Faster way]
>create table t1 as with q1 as (select sum(quantityordered) as monthlyquantity,year_id,month_id from sales_order_orc group by year_id,month_id order by year_id,month_id) select * from q1;
>select monthlyquantity,month_id,year_id from t1 where t1.monthlyquantity in (select max(monthlyquantity) from t1 group by year_id);
Total MapReduce CPU Time Spent: 2 seconds 640 msec
monthlyquantity	month_id	year_id
10179	11	2003
10678	11	2004
4357	5	2005

[or using partition on year]
>create table yearpart (monthlyquantity bigint,month_id int)partitioned by (year_id int) stored as orc; 
>insert overwrite table yearpart partition(year_id) select sum(quantityordered) as monthlyquantity,month_id,year_id from sales_order_orc group by year_id,month_id order by year_id,month_id;
>select monthlyquantity,month_id,year_id from yearpart where yearpart.monthlyquantity in (select max(monthlyquantity) from yearpart group by year_id);
Total MapReduce CPU Time Spent: 2 seconds 640 msec
monthlyquantity	month_id	year_id
10179	11	2003
10678	11	2004
4357	5	2005

------------------------------------------------------------------------------------------------------------------------------------------------
Scenario Based questions:

Q. Will the reducer work or not if you use “Limit 1” in any HiveQL query?

Yes as long as we are using group by or other aggregation functions in the query reducer will still work.

Q. Suppose I have installed Apache Hive on top of my Hadoop cluster using default metastore configuration. Then, what will happen if we have multiple clients trying to access Hive at the same time? 

Multiple clients accessing Hive at the same time will get an error as the default configuration only allows one connection but in cloudera v5.13 third party metastore is mySql which is set as standalone metastore allowing for multiple connections. Below is the hive-site.xml found in /etc/hive/conf/ directory. 
"""
>cat hive-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

  <!-- Hive Configuration can either be stored in this file or in the hadoop configuration files  -->
  <!-- that are implied by Hadoop setup variables.                                                -->
  <!-- Aside from Hadoop setup variables - this file is provided as a convenience so that Hive    -->
  <!-- users do not have to edit hadoop configuration files (that may be managed as a centralized -->
  <!-- resource).                                                                                 -->

  <!-- Hive Execution Parameters -->

  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://127.0.0.1/metastore?createDatabaseIfNotExist=true</value>
    <description>JDBC connect string for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>cloudera</value>
  </property>

  <property>
    <name>hive.hwi.war.file</name>
    <value>/usr/lib/hive/lib/hive-hwi-0.8.1-cdh4.0.0.jar</value>
    <description>This is the WAR file with the jsp content for Hive Web Interface</description>
  </property>

  <property>
    <name>datanucleus.fixedDatastore</name>
    <value>true</value>
  </property>

  <property>
    <name>datanucleus.autoCreateSchema</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.metastore.uris</name>
    <value>thrift://127.0.0.1:9083</value>
    <description>IP address (or fully-qualified domain name) and port of the metastore host</description>
  </property>
</configuration>
"""

Q.Suppose, I create a table that contains details of all the transactions done by the customers: CREATE TABLE transaction_details (cust_id INT, amount FLOAT, month STRING, country STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘,’ ;
Now, after inserting 50,000 records in this table, I want to know the total revenue generated for each month. But, Hive is taking too much time in processing this query. How will you solve this problem and list the steps that I will be taking in order to do so?

Partitioning the table on month field will reduce the time it takes for the query to search whole record.

>create table transactions_monthly(cust_id INT,amount FLOAT,country STRING) partitioned by (month STRING) row format delimited fields terminated by ',';
>set hive.exec.dynamic.partition =true;
>set hive.exec.dynamic.partition.mode = nonstrict;
>insert overwrite table transactions_monthly partition(month) select cust_id,amount,country,month from transaction_details;
>select sum(amount),month from transactions_monthly group by month;   

Q.How can you add a new partition for the month December in the above partitioned table?
> alter table transactions_monthly add partition(month='december');

Q.I am inserting data into a table based on partitions dynamically. But, I received an error – FAILED ERROR IN SEMANTIC ANALYSIS: Dynamic partition strict mode requires at least one static partition column. How will you remove this error?
No static partition was explicitly mentioned as we are doing dynamic partitioning so it has to be enabled first.
>set hive.exec.dynamic.partition =true;
>set hive.exec.dynamic.partition.mode = nonstrict;


Q.Suppose, I have a CSV file – ‘sample.csv’ present in ‘/temp’ directory with the following entries:
id first_name last_name email gender ip_address
How will you consume this CSV file into the Hive warehouse using built-in SerDe
1,"chris","hemsworth","chrishem@gmail.com","male","192.168.0.2"

>create table emp(id int,first_name string,last_name string,email string,gender string,ip_address string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile tblproperties("skip.header.line.count"="1");
>load data local inpath '/temp/' into table emp;

Q.Suppose, I have a lot of small CSV files present in the input directory in HDFS and I want to create a single Hive table corresponding to these files. The data in these files are in the format: {id, name, e-mail, country}. Now, as we know, Hadoop performance degrades when we use lots of small files.
So, how will you solve this problem where we want to create a single Hive table for lots of small files without degrading the performance of the system?



Q.LOAD DATA LOCAL INPATH ‘Home/country/state/’
OVERWRITE INTO TABLE address;
The following statement failed to execute. What can be the cause?

Is it possible to add 100 nodes when we already have 100 nodes in Hive? If yes, how?

------------------------------------------------------------------------------------------------------------------------------------------------
Hive Practical questions:

Hive Join operations

Create a  table named CUSTOMERS(ID | NAME | AGE | ADDRESS   | SALARY)
#id,name,address,salary
#1,dave,123street,3000
#2,ellen,45avenue,2000
#3,kevin,62roadstreet,2222
#4,maggie,82lane,5000

> create table CUSTOMERS(ID INT,NAME STRING,ADDRESS STRING,SALARY BIGINT) row format delimited fields terminated by ',' stored as textfile tblproperties("skip.header.line.count" = "1");
>load data local inpath '/home/cloudera/bigdata/first.txt' into table CUSTOMERS;

Create a Second  table ORDER(OID | DATE | CUSTOMER_ID | AMOUNT
)
#oid,date,customer_id,amount
#23,23-03-2021,3,210
#12,18-04-2022,5,67
#4,03-12-2021,2,89
#5,03-12-2021,2,22
#45,09-09-2020,6,333
#63,21-10-2021,4,1627

> create table ORDERS(OID INT,DATE STRING,CUSTOMER_ID INT,AMOUNT BIGINT) row format delimited fields terminated by ',' stored as textfile tblproperties("skip.header.line.count" = "1");
>load data local inpath '/home/cloudera/bigdata/second.txt' into table ORDERS;

Now perform different joins operations on top of these tables
(Inner JOIN, LEFT OUTER JOIN ,RIGHT OUTER JOIN ,FULL OUTER JOIN)

#INNER JOIN
>select c.id,c.name,o.oid,o.date,o.amount from customers as c join orders as o on c.id = o.customer_id;
c.id    c.name  o.oid   o.date  o.amount
3       kevin   23      23-03-2021      210
2       ellen   4       03-12-2021      89
2       ellen   5       03-12-2021      22
4       maggie  63      21-10-2021      1627

#LEFT OUTER JOIN
>select c.id,c.name,o.oid,o.date,o.amount from customers as c left join orders as o on c.id = o.customer_id;
c.id    c.name  o.oid   o.date  o.amount
1       dave    NULL    NULL    NULL
2       ellen   4       03-12-2021      89
2       ellen   5       03-12-2021      22
3       kevin   23      23-03-2021      210
4       maggie  63      21-10-2021      1627



#RIGHT OUTER JOIN
>select c.id,c.name,o.oid,o.date,o.amount from customers as c right join orders as o on c.id = o.customer_id;
c.id    c.name  o.oid   o.date  o.amount
3       kevin   23      23-03-2021      210
NULL    NULL    12      18-04-2022      67
2       ellen   4       03-12-2021      89
2       ellen   5       03-12-2021      22
NULL    NULL    45      09-09-2020      333
4       maggie  63      21-10-2021      1627

#FULL OUTER JOIN
>select c.id,c.name,o.oid,o.date,o.amount from customers as c left join orders as o on c.id = o.customer_id;

c.id    c.name  o.oid   o.date  o.amount
1       dave    NULL    NULL    NULL
2       ellen   5       03-12-2021      22
2       ellen   4       03-12-2021      89
3       kevin   23      23-03-2021      210
4       maggie  63      21-10-2021      1627
NULL    NULL    12      18-04-2022      67
NULL    NULL    45      09-09-2020      333
------------------------------------------------------------------------------------------------------------------------------------------------

BUILD A DATA PIPELINE WITH HIVE

Download a data from the given location - 
https://archive.ics.uci.edu/ml/machine-learning-databases/00360/

1. Create a hive table as per given schema in your dataset 

>create table airquality(DATE string,TIME string,CO string,TINOXIDE_CO int,NMHC int,C6H6 string,TITANIA_NMHC int,NOX int,TUNGOXIDE_NOX int,NO2 int,TUNGOXIDE_NO2 int,INDIUM_O3 int,TEMPERATURE string,RELATIVE_HUMIDITY string,ABSOLUTE_HUMIDITY string) row format delimited fields terminated by '\u0059' stored as textfile tblproperties("skip.header.line.count"="1");

2. try to place a data into table location

>hadoop fs -copyFromLocal '/home/cloudera/Downloads/AirQualityUCI.csv' hdfs://quickstart.cloudera:8020/user/hive/warehouse/hiveassignment.db/airquality
>hadoop fs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/hiveassignment.db/airquality                                         Found 1 items
-rw-r--r--   1 cloudera supergroup     785065 2022-09-22 13:30 hdfs://quickstart.cloudera:8020/user/hive/warehouse/hiveassignment.db/airquality/AirQualityUCI.csv

#some datatype conversions using views
>create view airquality3 as select cast(to_date(from_unixtime(unix_timestamp(DATE ,'dd/MM/yyyy'), 'yyyy-MM-dd')) as date) as DATE,from_unixtime(unix_timestamp(TIME, "HH.mm.ss"),"HH:mm:ss") as TIME,cast(regexp_replace(CO, ',', '.') as decimal(5,2)) as CO,TINOXIDE_CO,NMHC,cast(regexp_replace(C6H6, ',', '.') as decimal(5,2)) as C6H6,TITANIA_NMHC,NOX,TUNGOXIDE_NOX,NO2,TUNGOXIDE_NO2,INDIUM_O3,cast(regexp_replace(TEMPERATURE, ',', '.') as decimal(5,2)) as TEMPERATURE,cast(regexp_replace(RELATIVE_HUMIDITY, ',', '.') as decimal(5,2)) as RELATIVE_HUMIDITY,cast(regexp_replace(ABSOLUTE_HUMIDITY, ',', '.') as decimal(7,5)) as ABSOLUTE_HUMIDITY from airquality;

>describe airquality3;
date                    date
time                    string
co                      decimal(5,2)
tinoxide_co             int
nmhc                    int
c6h6                    decimal(5,2)
titania_nmhc            int
nox                     int
tungoxide_nox           int
no2                     int
tungoxide_no2           int
indium_o3               int
temperature             decimal(5,2)
relative_humidity       decimal(5,2)
absolute_humidity       decimal(7,5)

3. Perform a select operation 

>select * from airquality3 limit 4;
airquality3.date        airquality3.time        airquality3.co  airquality3.tinoxide_co   airquality3.nmhc        airquality3.c6h6        airquality3.titania_nmhc airquality3.nox  airquality3.tungoxide_nox       airquality3.no2 airquality3.tungoxide_no2 airquality3.indium_o3   airquality3.temperature airquality3.relative_humidity     airquality3.absolute_humidity
2004-03-10      18:12:00        2.6     1360    150     11.9    1046    166     1056      113     1692    1268    13.6    48.9    0.7578
2004-03-10      19:12:00        2       1292    112     9.4     955     103     1174      92      1559    972     13.3    47.7    0.7255
2004-03-10      20:12:00        2.2     1402    88      9       939     131     1140      114     1555    1074    11.9    54      0.7502
2004-03-10      21:12:00        2.2     1376    80      9.2     948     172     1092      122     1584    1203    11      60      0.7867

4. Fetch the result of the select operation in your local as a csv file .

>create table airquality_csv row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile as select * from airquality3;
>hadoop fs -cat hdfs://quickstart.cloudera:8020/user/hive/warehouse/hiveassignment.db/airquality_csv/* > ~/airquality_output.csv
 
5. Perform group by operation .

>select max(absolute_humidity)as Maximum_humidity,month(date)as Month,year(date) as Year from airquality3 group by month(date),year(date);
maximum_humidity        month   year
NULL    NULL    NULL
1.0567  1       2005
1.0859  2       2005
1.0945  3       2004
1.393   3       2005
1.4852  4       2004
0.8642  4       2005
1.6296  5       2004
1.939   6       2004
2.0042  7       2004
2.1806  8       2004
2.231   9       2004
2.0224  10      2004
1.98    11      2004
1.3713  12      2004
 
7. Perform filter operation at least 5 kinds of filter examples . 

>select * from airquality3 where month(date) between 2 and 6  limit 5;

airquality3.date        airquality3.time        airquality3.co  airquality3.tinoxide_co airquality3.nmhc        airquality3.c6h6        airquality3.titania_nmhcairquality3.nox airquality3.tungoxide_nox       airquality3.no2 airquality3.tungoxide_no2       airquality3.indium_o3   airquality3.temperature airquality3.relative_humidity   airquality3.absolute_humidity
2004-03-10      18:12:00        2.6     1360    150     11.9    1046    166    1056     113     1692    1268    13.6    48.9    0.7578
2004-03-10      19:12:00        2       1292    112     9.4     955     103    1174     92      1559    972     13.3    47.7    0.7255
2004-03-10      20:12:00        2.2     1402    88      9       939     131    1140     114     1555    1074    11.9    54      0.7502
2004-03-10      21:12:00        2.2     1376    80      9.2     948     172    1092     122     1584    1203    11      60      0.7867
2004-03-10      22:12:00        1.6     1272    51      6.5     836     131    1205     116     1490    1110    11.2    59.6    0.7888

>select * from airquality3 where month(date) = 2 or month(date) = 5 limit 5;

airquality3.date        airquality3.time        airquality3.co  airquality3.tinoxide_co airquality3.nmhc        airquality3.c6h6        airquality3.titania_nmhcairquality3.nox airquality3.tungoxide_nox       airquality3.no2 airquality3.tungoxide_no2       airquality3.indium_o3   airquality3.temperature airquality3.relative_humidity   airquality3.absolute_humidity
2004-05-01      00:12:00        3.5     1425    275     15.2    1155    185    709      110     1936    1789    17.8    66.8    1.346
2004-05-01      01:12:00        2.4     1179    -200    9.3     951     129    826      84      1724    1323    17.3    68.3    1.3346
2004-05-01      02:12:00        1.6     1047    -200    6.5     833     85     939      71      1647    1081    16.5    70.2    1.3099
2004-05-01      03:12:00        1.3     1009    -200    6.3     825     -200   950      -200    1629    938     15.7    73.1    1.2902
2004-05-01      04:12:00        -200    882     -200    3.5     685     35     1134     42      1492    673     16.2    69.9    1.2756

> select * from airquality3 where month(date) = 4 and year(date) != 2004 limit 5;
airquality3.date        airquality3.time        airquality3.co  airquality3.tinoxide_co airquality3.nmhc        airquality3.c6h6        airquality3.titania_nmhcairquality3.nox airquality3.tungoxide_nox       airquality3.no2 airquality3.tungoxide_no2       airquality3.indium_o3   airquality3.temperature airquality3.relative_humidity   airquality3.absolute_humidity
2005-04-01      00:12:00        0.7     848     -200    1.5     541     69     1067     61      937     392     15.1    44.5    0.7569
2005-04-01      01:12:00        0.6     818     -200    1       497     53     1198     50      885     347     14.6    43      0.7108
2005-04-01      02:12:00        0.5     848     -200    1.1     509     36     1126     35      882     341     14.5    43.7    0.7163
2005-04-01      03:12:00        0.5     826     -200    0.9     488     30     1187     29      895     322     13.6    46.7    0.7245
2005-04-01      04:12:00        -200    818     -200    0.8     473     47     1257     41      898     323     13.7    48.8    0.7606

> select * from airquality3 where month(date) in (7,8) and year(date) = 2004 limit 5;
airquality3.date        airquality3.time        airquality3.co  airquality3.tinoxide_co airquality3.nmhc        airquality3.c6h6        airquality3.titania_nmhcairquality3.nox airquality3.tungoxide_nox       airquality3.no2 airquality3.tungoxide_no2       airquality3.indium_o3   airquality3.temperature airquality3.relative_humidity   airquality3.absolute_humidity
2004-07-01      00:12:00        2.3     1109    -200    12.9    1080    111    696      102     1874    1190    27.1    47.4    1.6701
2004-07-01      01:12:00        1.5     1032    -200    9.9     974     66     763      77      1800    982     26.2    49.4    1.6555
2004-07-01      02:12:00        0.9     893     -200    5.1     767     36     918      50      1607    805     26.9    49.3    1.7196
2004-07-01      03:12:00        0.6     848     -200    2.8     642     -200   1079     -200    1536    654     26.3    50.8    1.7058
2004-07-01      04:12:00        0.6     850     -200    3.2     664     31     1038     40      1568    727     24.9    54.6    1.6908

>select * from airquality3 where time like '02%' limit 5;
airquality3.date        airquality3.time        airquality3.co  airquality3.tinoxide_co airquality3.nmhc        airquality3.c6h6        airquality3.titania_nmhcairquality3.nox airquality3.tungoxide_nox       airquality3.no2 airquality3.tungoxide_no2       airquality3.indium_o3   airquality3.temperature airquality3.relative_humidity   airquality3.absolute_humidity
2004-03-11      02:12:00        0.9     1094    24      2.3     609     45     1579     60      1276    620     10.7    59.7    0.7648
2004-03-12      02:12:00        1.4     988     40      4.1     718     82     1396     91      1304    692     7.1     61.8    0.6276
2004-03-13      02:12:00        1.6     1184    43      5.4     782     83     1176     82      1365    1043    8.8     63.9    0.7256
2004-03-14      02:12:00        2.5     1367    92      8.6     925     128    953      104     1543    1337    12.5    58.9    0.8537
2004-03-15      02:12:00        1.8     1224    66      7       855     108    998      88      1566    1149    13.4    61.3    0.9361

8. show and example of regex operation

9. alter table operation 
>alter table airquality4 rename to airnew;

10 . drop table operation

>drop table airquality_csv;
>drop view airquality2;

12 . order by operation . 

>select max(relative_humidity) as maximum_RH,month(date) as month,year(date) as year from airquality3 group by month(date),year(date) order by month,year desc;

maximum_rh      month   year
NULL    NULL    NULL
86.6    1       2005
86.6    2       2005
84      3       2005
83.2    3       2004
63.1    4       2005
82.4    4       2004
85.2    5       2004
82.3    6       2004
69.3    7       2004
81.8    8       2004
87.2    9       2004
86.5    10      2004
87.1    11      2004
88.7    12      2004

13 . where clause operations you have to perform . 

>select * from airquality3 where month(date) = 5 limit 5;

airquality3.date        airquality3.time        airquality3.co  airquality3.tinoxide_co airquality3.nmhc        airquality3.c6h6        airquality3.titania_nmhcairquality3.nox airquality3.tungoxide_nox       airquality3.no2 airquality3.tungoxide_no2       airquality3.indium_o3   airquality3.temperature airquality3.relative_humidity   airquality3.absolute_humidity
2004-05-01      00:12:00        3.5     1425    275     15.2    1155    185    709      110     1936    1789    17.8    66.8    1.346
2004-05-01      01:12:00        2.4     1179    -200    9.3     951     129    826      84      1724    1323    17.3    68.3    1.3346
2004-05-01      02:12:00        1.6     1047    -200    6.5     833     85     939      71      1647    1081    16.5    70.2    1.3099
2004-05-01      03:12:00        1.3     1009    -200    6.3     825     -200   950      -200    1629    938     15.7    73.1    1.2902
2004-05-01      04:12:00        -200    882     -200    3.5     685     35     1134     42      1492    673     16.2    69.9    1.2756

14 . sorting operation you have to perform . 

>select max(relative_humidity) as maximum_RH,month(date) as month,year(date) as year from airquality3 group by month(date),year(date) sort by month,year desc;
maximum_rh      month   year
NULL    NULL    NULL
86.6    1       2005
86.6    2       2005
84      3       2005
83.2    3       2004
63.1    4       2005
82.4    4       2004
85.2    5       2004
82.3    6       2004
69.3    7       2004
81.8    8       2004
87.2    9       2004
86.5    10      2004
87.1    11      2004
88.7    12      2004

15 . distinct operation you have to perform . 

> select distinct(year(date)) as year from airquality3;
year
NULL
2004
2005

16 . like an operation you have to perform . 

>select * from airquality3 where time like '02%';

17 . union operation you have to perform . 

>select sum(relative_humidity) as total_humidity, year(date) as year from airquality3 group by year(date) union all select sum(relative_humidity) as total_humidity,year(date) as year from airquality3 group by year(date);
_u1.total_humidity      _u1.year
NULL    NULL
286476.5        2004
82988.2 2005
NULL    NULL
286476.5        2004
82988.2 2005

18 . table view operation you have to perform . 

>create view airquality3 as select cast(to_date(from_unixtime(unix_timestamp(DATE ,'dd/MM/yyyy'), 'yyyy-MM-dd')) as date) as DATE,from_unixtime(unix_timestamp(TIME, "HH.mm.ss"),"HH:mm:ss") as TIME,cast(regexp_replace(CO, ',', '.') as decimal(5,2)) as CO,TINOXIDE_CO,NMHC,cast(regexp_replace(C6H6, ',', '.') as decimal(5,2)) as C6H6,TITANIA_NMHC,NOX,TUNGOXIDE_NOX,NO2,TUNGOXIDE_NO2,INDIUM_O3,cast(regexp_replace(TEMPERATURE, ',', '.') as decimal(5,2)) as TEMPERATURE,cast(regexp_replace(RELATIVE_HUMIDITY, ',', '.') as decimal(5,2)) as RELATIVE_HUMIDITY,cast(regexp_replace(ABSOLUTE_HUMIDITY, ',', '.') as decimal(7,5)) as ABSOLUTE_HUMIDITY from airquality;
